{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bc43574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import SiglipProcessor, SiglipModel\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betöltés\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SiglipModel.from_pretrained(\"google/siglip-base-patch16-224\").to(device)\n",
    "processor = SiglipProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "\n",
    "# Adatok\n",
    "embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
    "infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
    "with open(\"C:/Users/Adam/Desktop/applied_ml/custom_captions.json\", encoding=\"utf-8\") as f:\n",
    "    class_texts = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94984a",
   "metadata": {},
   "source": [
    "# Top 1-ek hasonlósága"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adam\\miniconda3\\envs\\main_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\2972408891.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\2972408891.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
      "Top-1 similarity számolása: 100%|██████████| 102/102 [00:01<00:00, 53.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  top1_similarity\n",
      "0         1          0.16427\n",
      "1         2          0.13237\n",
      "2         3          0.16147\n",
      "3         4          0.15085\n",
      "4         5          0.14088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Eredmények tárolása\n",
    "top1_results = []\n",
    "\n",
    "# Végigmegyünk mind a 102 osztályon\n",
    "for class_id in tqdm(range(1, 103), desc=\"Top-1 similarity számolása\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Szöveg → embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity az összes képre\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze()\n",
    "\n",
    "    # Top-1 érték kinyerése\n",
    "    top1_score = similarities.max().item()\n",
    "\n",
    "    top1_results.append({\n",
    "        \"class_id\": class_id,\n",
    "        \"top1_similarity\": round(top1_score, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame-be tesszük\n",
    "df_top1 = pd.DataFrame(top1_results)\n",
    "print(df_top1.head())\n",
    "\n",
    "# CSV-be mentés (ha szeretnéd)\n",
    "df_top1.to_csv(\"C:/Users/Adam/Desktop/applied_ml/class_top1_similarity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\1393463316.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\1393463316.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
      "Precision@N számolása: 100%|██████████| 102/102 [00:01<00:00, 69.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  class_size  correct_in_topN  precision_at_class_size\n",
      "0         1          27               20                  0.74074\n",
      "1         2          49               40                  0.81633\n",
      "2         3          36               25                  0.69444\n",
      "3         4          44               39                  0.88636\n",
      "4         5          54               39                  0.72222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Eredmények tárolása\n",
    "precision_results = []\n",
    "\n",
    "# Végigmegyünk mind a 102 osztályon\n",
    "for class_id in tqdm(range(1, 103), desc=\"Precision@N számolása\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Szöveg → embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity az összes képre\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze()\n",
    "\n",
    "    # Az adott osztályhoz tartozó képek száma\n",
    "    class_size = sum(1 for info in infos if int(info[\"label\"]) == class_id)\n",
    "\n",
    "    # Top N visszakeresés (N = class_size)\n",
    "    top_indices = similarities.topk(class_size).indices\n",
    "\n",
    "    # Hány top kép van valóban a class_id osztályban?\n",
    "    correct = sum(1 for idx in top_indices if int(infos[idx][\"label\"]) == class_id)\n",
    "\n",
    "    precision = correct / class_size if class_size > 0 else 0.0\n",
    "\n",
    "    precision_results.append({\n",
    "        \"class_id\": class_id,\n",
    "        \"class_size\": class_size,\n",
    "        \"correct_in_topN\": correct,\n",
    "        \"precision_at_class_size\": round(precision, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame-be tesszük\n",
    "df_precision = pd.DataFrame(precision_results)\n",
    "print(df_precision.head())\n",
    "\n",
    "# CSV mentés\n",
    "df_precision.to_csv(\"C:/Users/Adam/Desktop/applied_ml/class_precision_at_class_size.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\944431738.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\944431738.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
      "Recall cutoff számolása: 100%|██████████| 102/102 [00:04<00:00, 23.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  class_size  topN_70  topN_80  topN_90  topN_95  threshold_70  \\\n",
      "0         1          27       26       34       50       51       0.13915   \n",
      "1         2          49       37       45       75       86       0.09562   \n",
      "2         3          36       39       47       67      227       0.11541   \n",
      "3         4          44       32       39       45       52       0.12268   \n",
      "4         5          54       50       80       90      114       0.11872   \n",
      "\n",
      "   threshold_80  threshold_90  threshold_95  \n",
      "0       0.13033       0.11447       0.11366  \n",
      "1       0.08807       0.07893       0.07664  \n",
      "2       0.11272       0.10759       0.08375  \n",
      "3       0.11493       0.10914       0.10568  \n",
      "4       0.11281       0.11144       0.10730  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Kimenet tárolása\n",
    "recall_results = []\n",
    "\n",
    "# Osztályonként végigmegyünk\n",
    "for class_id in tqdm(range(1, 103), desc=\"Recall cutoff számolása\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Text embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity az összes képre\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze()\n",
    "    sorted_indices = torch.argsort(similarities, descending=True)\n",
    "\n",
    "    # Bináris vektor: 1, ha helyes osztályba tartozik\n",
    "    binary_hits = [1 if int(infos[i][\"label\"]) == class_id else 0 for i in sorted_indices]\n",
    "    cumsum_hits = np.cumsum(binary_hits) # a visszakeresett listában hány jó találat van eddig összesítve\n",
    "\n",
    "    class_size = sum(binary_hits)  # az adott osztályhoz tartozó képek száma\n",
    "    recall_targets = {\n",
    "        70: int(np.ceil(class_size * 0.70)),\n",
    "        80: int(np.ceil(class_size * 0.80)),\n",
    "        90: int(np.ceil(class_size * 0.90)),\n",
    "        95: int(np.ceil(class_size * 0.95)),\n",
    "    }\n",
    "\n",
    "    topN_at = {}\n",
    "    threshold_at = {}\n",
    "\n",
    "    for perc, target in recall_targets.items():\n",
    "        found_index = next((i for i, val in enumerate(cumsum_hits) if val >= target), None) # keressük azt az első olyan indexet, ahol már elértük vagy túlléptük a kívánt számú helyes találatot\n",
    "        if found_index is not None:\n",
    "            topN_at[f\"topN_{perc}\"] = found_index + 1  # index → N\n",
    "            threshold_at[f\"threshold_{perc}\"] = round(similarities[sorted_indices[found_index]].item(), 5)\n",
    "        else:\n",
    "            topN_at[f\"topN_{perc}\"] = None\n",
    "            threshold_at[f\"threshold_{perc}\"] = None\n",
    "\n",
    "    result = {\n",
    "        \"class_id\": class_id,\n",
    "        \"class_size\": class_size,\n",
    "        **topN_at,\n",
    "        **threshold_at\n",
    "    }\n",
    "\n",
    "    recall_results.append(result)\n",
    "\n",
    "# Eredmények táblázatba\n",
    "df_recall = pd.DataFrame(recall_results)\n",
    "print(df_recall.head())\n",
    "\n",
    "# Mentés CSV-be\n",
    "df_recall.to_csv(\"C:/Users/Adam/Desktop/applied_ml/class_recall_cutoffs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965c89a",
   "metadata": {},
   "source": [
    "# bert topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a12cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\4052214356.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\4052214356.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
      "AP számolása: 100%|██████████| 102/102 [00:02<00:00, 39.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  average_precision\n",
      "0         1            0.79286\n",
      "1         2            0.91528\n",
      "2         3            0.78243\n",
      "3         4            0.96496\n",
      "4         5            0.81550\n",
      "\n",
      "Mean Average Precision (mAP): 0.87911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Eredmények\n",
    "ap_results = []\n",
    "\n",
    "for class_id in tqdm(range(1, 103), desc=\"AP számolása\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Szöveg embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze().numpy()\n",
    "\n",
    "    # Binary ground truth: 1 ha jó osztály, különben 0\n",
    "    gt_labels = [1 if int(info[\"label\"]) == class_id else 0 for info in infos]\n",
    "\n",
    "    # Average precision\n",
    "    if sum(gt_labels) > 0:\n",
    "        ap = average_precision_score(gt_labels, similarities)\n",
    "    else:\n",
    "        ap = 0.0\n",
    "\n",
    "    ap_results.append({\n",
    "        \"class_id\": class_id,\n",
    "        \"average_precision\": round(ap, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame + mAP\n",
    "df_ap = pd.DataFrame(ap_results)\n",
    "mean_ap = df_ap[\"average_precision\"].mean()\n",
    "print(df_ap.head())\n",
    "print(f\"\\nMean Average Precision (mAP): {round(mean_ap, 5)}\")\n",
    "\n",
    "# CSV mentés\n",
    "df_ap.to_csv(\"C:/Users/Adam/Desktop/applied_ml/class_average_precision.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455f70c",
   "metadata": {},
   "source": [
    "# Innentől Image rész"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481c319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\115493850.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\115493850.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Cosine similarity mátrix számolása...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Top-1 keresés képenként: 100%|██████████| 6552/6552 [00:00<00:00, 75146.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kész: image_top1_similarity.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity mátrix (n x n)\n",
    "print(\"🧠 Cosine similarity mátrix számolása...\")\n",
    "embedding_matrix = embeddings.numpy()\n",
    "sim_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "# Diagonálisan 1-es lenne (önmagával) – ezt kilőjük\n",
    "np.fill_diagonal(sim_matrix, -1)\n",
    "\n",
    "# Eredmények tárolása\n",
    "top1_results = []\n",
    "\n",
    "for i in tqdm(range(sim_matrix.shape[0]), desc=\"Top-1 keresés képenként\"):\n",
    "    top1_idx = sim_matrix[i].argmax()\n",
    "    top1_sim = sim_matrix[i][top1_idx]\n",
    "\n",
    "    label_i = int(infos[i][\"label\"])\n",
    "    label_top1 = int(infos[top1_idx][\"label\"])\n",
    "    same_class = (label_i == label_top1)\n",
    "\n",
    "    top1_results.append({\n",
    "        \"image_index\": i,\n",
    "        \"top1_index\": top1_idx,\n",
    "        \"top1_similarity\": round(top1_sim, 5),\n",
    "        \"label\": label_i,\n",
    "        \"top1_label\": label_top1,\n",
    "        \"same_class\": same_class\n",
    "    })\n",
    "\n",
    "# Mentés\n",
    "df_top1 = pd.DataFrame(top1_results)\n",
    "df_top1.to_csv(\"C:/Users/Adam/Desktop/applied_ml/image_top1_similarity.csv\", index=False)\n",
    "print(\"✅ Kész: image_top1_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137e8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\1715302535.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\1715302535.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Cosine similarity mátrix számolása...\n",
      "📊 Recall@K számolása minden képre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recall képenként: 100%|██████████| 6552/6552 [00:08<00:00, 764.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Átlagos Recall@K értékek:\n",
      "Recall@1: 0.01568\n",
      "Recall@5: 0.07727\n",
      "Recall@10: 0.15266\n",
      "Recall@20: 0.29798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity mátrix (n x n)\n",
    "print(\"🧠 Cosine similarity mátrix számolása...\")\n",
    "embedding_matrix = embeddings.numpy()\n",
    "sim_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "# Diagonálisan -1, hogy önmagát ne hozza vissza\n",
    "np.fill_diagonal(sim_matrix, -1)\n",
    "\n",
    "# Recall@K értékek\n",
    "K_values = [1, 5, 10, 20]\n",
    "recall_records = []\n",
    "\n",
    "print(\"📊 Recall@K számolása minden képre...\")\n",
    "for i in tqdm(range(sim_matrix.shape[0]), desc=\"Recall képenként\"):\n",
    "    true_label = int(infos[i][\"label\"])\n",
    "    top_indices = np.argsort(-sim_matrix[i])  # descending sorrend\n",
    "\n",
    "    recalls = {}\n",
    "    # Az aktuális osztályhoz tartozó képek száma (önmagát kivéve)\n",
    "    total_same_class = sum(1 for j in range(len(infos)) if j != i and int(infos[j][\"label\"]) == true_label)\n",
    "\n",
    "    for k in K_values:\n",
    "        top_k = top_indices[:k]\n",
    "        correct = sum(1 for j in top_k if int(infos[j][\"label\"]) == true_label)\n",
    "        recall = correct / total_same_class if total_same_class > 0 else 0.0\n",
    "        recalls[f\"recall@{k}\"] = round(recall, 5)\n",
    "\n",
    "    recall_records.append({\n",
    "        \"image_index\": i,\n",
    "        \"label\": true_label,\n",
    "        **recalls\n",
    "    })\n",
    "\n",
    "# DataFrame mentés\n",
    "df_recall = pd.DataFrame(recall_records)\n",
    "df_recall.to_csv(\"C:/Users/Adam/Desktop/applied_ml/image_recall_at_k.csv\", index=False)\n",
    "\n",
    "# Átlag recall@k kiírás\n",
    "mean_recalls = df_recall[[f\"recall@{k}\" for k in K_values]].mean()\n",
    "print(\"\\n📈 Átlagos Recall@K értékek:\")\n",
    "for k in K_values:\n",
    "    print(f\"Recall@{k}: {round(mean_recalls[f'recall@{k}'], 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\349315602.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\349315602.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Cosine similarity mátrix számolása...\n",
      "📊 Average Precision számítása minden képre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AP per image: 100%|██████████| 6552/6552 [00:13<00:00, 486.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_index  label  average_precision\n",
      "0            0      1            0.80528\n",
      "1            1      1            0.80784\n",
      "2            2      1            0.80397\n",
      "3            3      1            0.79885\n",
      "4            4      1            0.77852\n",
      "\n",
      "📈 Mean Average Precision (mAP) for images: 0.8723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity mátrix\n",
    "print(\"🧠 Cosine similarity mátrix számolása...\")\n",
    "embedding_matrix = embeddings.numpy()\n",
    "sim_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "# Saját magát nem hasonlítjuk (AP-ben nincs értelme)\n",
    "np.fill_diagonal(sim_matrix, -1)\n",
    "\n",
    "# Eredmények\n",
    "ap_results = []\n",
    "\n",
    "print(\"📊 Average Precision számítása minden képre...\")\n",
    "for i in tqdm(range(sim_matrix.shape[0]), desc=\"AP per image\"):\n",
    "    label = int(infos[i][\"label\"])\n",
    "\n",
    "    # Ground truth: 1 ha ugyanabba az osztályba tartozik, különben 0 (önmagát nem számítjuk)\n",
    "    gt = np.array([1 if int(infos[j][\"label\"]) == label else 0 for j in range(len(infos))])\n",
    "    gt[i] = 0  # önmagát nullázzuk\n",
    "\n",
    "    scores = sim_matrix[i]\n",
    "\n",
    "    if gt.sum() > 0:\n",
    "        ap = average_precision_score(gt, scores)\n",
    "    else:\n",
    "        ap = 0.0\n",
    "\n",
    "    ap_results.append({\n",
    "        \"image_index\": i,\n",
    "        \"label\": label,\n",
    "        \"average_precision\": round(ap, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame + mAP\n",
    "df_ap = pd.DataFrame(ap_results)\n",
    "mean_ap = df_ap[\"average_precision\"].mean()\n",
    "print(df_ap.head())\n",
    "print(f\"\\n📈 Mean Average Precision (mAP) for images: {round(mean_ap, 5)}\")\n",
    "\n",
    "# Mentés\n",
    "df_ap.to_csv(\"C:/Users/Adam/Desktop/applied_ml/image_average_precision.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
