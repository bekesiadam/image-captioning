{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bc43574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import SiglipProcessor, SiglipModel\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bet√∂lt√©s\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SiglipModel.from_pretrained(\"google/siglip-base-patch16-224\").to(device)\n",
    "processor = SiglipProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "\n",
    "# Adatok\n",
    "embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
    "infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
    "with open(\"C:/Users/Adam/Desktop/applied_ml/custom_captions.json\", encoding=\"utf-8\") as f:\n",
    "    class_texts = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94984a",
   "metadata": {},
   "source": [
    "# Top 1-ek hasonl√≥s√°ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adam\\miniconda3\\envs\\main_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\2972408891.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\2972408891.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
      "Top-1 similarity sz√°mol√°sa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102/102 [00:01<00:00, 53.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  top1_similarity\n",
      "0         1          0.16427\n",
      "1         2          0.13237\n",
      "2         3          0.16147\n",
      "3         4          0.15085\n",
      "4         5          0.14088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Eredm√©nyek t√°rol√°sa\n",
    "top1_results = []\n",
    "\n",
    "# V√©gigmegy√ºnk mind a 102 oszt√°lyon\n",
    "for class_id in tqdm(range(1, 103), desc=\"Top-1 similarity sz√°mol√°sa\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Sz√∂veg ‚Üí embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity az √∂sszes k√©pre\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze()\n",
    "\n",
    "    # Top-1 √©rt√©k kinyer√©se\n",
    "    top1_score = similarities.max().item()\n",
    "\n",
    "    top1_results.append({\n",
    "        \"class_id\": class_id,\n",
    "        \"top1_similarity\": round(top1_score, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame-be tessz√ºk\n",
    "df_top1 = pd.DataFrame(top1_results)\n",
    "print(df_top1.head())\n",
    "\n",
    "# CSV-be ment√©s (ha szeretn√©d)\n",
    "df_top1.to_csv(\"C:/Users/Adam/Desktop/applied_ml/class_top1_similarity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\1393463316.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\1393463316.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
      "Precision@N sz√°mol√°sa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102/102 [00:01<00:00, 69.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  class_size  correct_in_topN  precision_at_class_size\n",
      "0         1          27               20                  0.74074\n",
      "1         2          49               40                  0.81633\n",
      "2         3          36               25                  0.69444\n",
      "3         4          44               39                  0.88636\n",
      "4         5          54               39                  0.72222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Eredm√©nyek t√°rol√°sa\n",
    "precision_results = []\n",
    "\n",
    "# V√©gigmegy√ºnk mind a 102 oszt√°lyon\n",
    "for class_id in tqdm(range(1, 103), desc=\"Precision@N sz√°mol√°sa\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Sz√∂veg ‚Üí embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity az √∂sszes k√©pre\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze()\n",
    "\n",
    "    # Az adott oszt√°lyhoz tartoz√≥ k√©pek sz√°ma\n",
    "    class_size = sum(1 for info in infos if int(info[\"label\"]) == class_id)\n",
    "\n",
    "    # Top N visszakeres√©s (N = class_size)\n",
    "    top_indices = similarities.topk(class_size).indices\n",
    "\n",
    "    # H√°ny top k√©p van val√≥ban a class_id oszt√°lyban?\n",
    "    correct = sum(1 for idx in top_indices if int(infos[idx][\"label\"]) == class_id)\n",
    "\n",
    "    precision = correct / class_size if class_size > 0 else 0.0\n",
    "\n",
    "    precision_results.append({\n",
    "        \"class_id\": class_id,\n",
    "        \"class_size\": class_size,\n",
    "        \"correct_in_topN\": correct,\n",
    "        \"precision_at_class_size\": round(precision, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame-be tessz√ºk\n",
    "df_precision = pd.DataFrame(precision_results)\n",
    "print(df_precision.head())\n",
    "\n",
    "# CSV ment√©s\n",
    "df_precision.to_csv(\"C:/Users/Adam/Desktop/applied_ml/class_precision_at_class_size.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\944431738.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\944431738.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
      "Recall cutoff sz√°mol√°sa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102/102 [00:04<00:00, 23.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  class_size  topN_70  topN_80  topN_90  topN_95  threshold_70  \\\n",
      "0         1          27       26       34       50       51       0.13915   \n",
      "1         2          49       37       45       75       86       0.09562   \n",
      "2         3          36       39       47       67      227       0.11541   \n",
      "3         4          44       32       39       45       52       0.12268   \n",
      "4         5          54       50       80       90      114       0.11872   \n",
      "\n",
      "   threshold_80  threshold_90  threshold_95  \n",
      "0       0.13033       0.11447       0.11366  \n",
      "1       0.08807       0.07893       0.07664  \n",
      "2       0.11272       0.10759       0.08375  \n",
      "3       0.11493       0.10914       0.10568  \n",
      "4       0.11281       0.11144       0.10730  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Kimenet t√°rol√°sa\n",
    "recall_results = []\n",
    "\n",
    "# Oszt√°lyonk√©nt v√©gigmegy√ºnk\n",
    "for class_id in tqdm(range(1, 103), desc=\"Recall cutoff sz√°mol√°sa\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Text embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity az √∂sszes k√©pre\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze()\n",
    "    sorted_indices = torch.argsort(similarities, descending=True)\n",
    "\n",
    "    # Bin√°ris vektor: 1, ha helyes oszt√°lyba tartozik\n",
    "    binary_hits = [1 if int(infos[i][\"label\"]) == class_id else 0 for i in sorted_indices]\n",
    "    cumsum_hits = np.cumsum(binary_hits) # a visszakeresett list√°ban h√°ny j√≥ tal√°lat van eddig √∂sszes√≠tve\n",
    "\n",
    "    class_size = sum(binary_hits)  # az adott oszt√°lyhoz tartoz√≥ k√©pek sz√°ma\n",
    "    recall_targets = {\n",
    "        70: int(np.ceil(class_size * 0.70)),\n",
    "        80: int(np.ceil(class_size * 0.80)),\n",
    "        90: int(np.ceil(class_size * 0.90)),\n",
    "        95: int(np.ceil(class_size * 0.95)),\n",
    "    }\n",
    "\n",
    "    topN_at = {}\n",
    "    threshold_at = {}\n",
    "\n",
    "    for perc, target in recall_targets.items():\n",
    "        found_index = next((i for i, val in enumerate(cumsum_hits) if val >= target), None) # keress√ºk azt az els≈ë olyan indexet, ahol m√°r el√©rt√ºk vagy t√∫ll√©pt√ºk a k√≠v√°nt sz√°m√∫ helyes tal√°latot\n",
    "        if found_index is not None:\n",
    "            topN_at[f\"topN_{perc}\"] = found_index + 1  # index ‚Üí N\n",
    "            threshold_at[f\"threshold_{perc}\"] = round(similarities[sorted_indices[found_index]].item(), 5)\n",
    "        else:\n",
    "            topN_at[f\"topN_{perc}\"] = None\n",
    "            threshold_at[f\"threshold_{perc}\"] = None\n",
    "\n",
    "    result = {\n",
    "        \"class_id\": class_id,\n",
    "        \"class_size\": class_size,\n",
    "        **topN_at,\n",
    "        **threshold_at\n",
    "    }\n",
    "\n",
    "    recall_results.append(result)\n",
    "\n",
    "# Eredm√©nyek t√°bl√°zatba\n",
    "df_recall = pd.DataFrame(recall_results)\n",
    "print(df_recall.head())\n",
    "\n",
    "# Ment√©s CSV-be\n",
    "df_recall.to_csv(\"C:/Users/Adam/Desktop/applied_ml/class_recall_cutoffs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965c89a",
   "metadata": {},
   "source": [
    "# bert topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a12cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\4052214356.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\4052214356.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
      "AP sz√°mol√°sa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102/102 [00:02<00:00, 39.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  average_precision\n",
      "0         1            0.79286\n",
      "1         2            0.91528\n",
      "2         3            0.78243\n",
      "3         4            0.96496\n",
      "4         5            0.81550\n",
      "\n",
      "Mean Average Precision (mAP): 0.87911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Eredm√©nyek\n",
    "ap_results = []\n",
    "\n",
    "for class_id in tqdm(range(1, 103), desc=\"AP sz√°mol√°sa\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Sz√∂veg embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze().numpy()\n",
    "\n",
    "    # Binary ground truth: 1 ha j√≥ oszt√°ly, k√ºl√∂nben 0\n",
    "    gt_labels = [1 if int(info[\"label\"]) == class_id else 0 for info in infos]\n",
    "\n",
    "    # Average precision\n",
    "    if sum(gt_labels) > 0:\n",
    "        ap = average_precision_score(gt_labels, similarities)\n",
    "    else:\n",
    "        ap = 0.0\n",
    "\n",
    "    ap_results.append({\n",
    "        \"class_id\": class_id,\n",
    "        \"average_precision\": round(ap, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame + mAP\n",
    "df_ap = pd.DataFrame(ap_results)\n",
    "mean_ap = df_ap[\"average_precision\"].mean()\n",
    "print(df_ap.head())\n",
    "print(f\"\\nMean Average Precision (mAP): {round(mean_ap, 5)}\")\n",
    "\n",
    "# CSV ment√©s\n",
    "df_ap.to_csv(\"C:/Users/Adam/Desktop/applied_ml/class_average_precision.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455f70c",
   "metadata": {},
   "source": [
    "# Innent≈ël Image r√©sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481c319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\115493850.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\115493850.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Cosine similarity m√°trix sz√°mol√°sa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Top-1 keres√©s k√©penk√©nt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6552/6552 [00:00<00:00, 75146.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ K√©sz: image_top1_similarity.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity m√°trix (n x n)\n",
    "print(\"üß† Cosine similarity m√°trix sz√°mol√°sa...\")\n",
    "embedding_matrix = embeddings.numpy()\n",
    "sim_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "# Diagon√°lisan 1-es lenne (√∂nmag√°val) ‚Äì ezt kil≈ëj√ºk\n",
    "np.fill_diagonal(sim_matrix, -1)\n",
    "\n",
    "# Eredm√©nyek t√°rol√°sa\n",
    "top1_results = []\n",
    "\n",
    "for i in tqdm(range(sim_matrix.shape[0]), desc=\"Top-1 keres√©s k√©penk√©nt\"):\n",
    "    top1_idx = sim_matrix[i].argmax()\n",
    "    top1_sim = sim_matrix[i][top1_idx]\n",
    "\n",
    "    label_i = int(infos[i][\"label\"])\n",
    "    label_top1 = int(infos[top1_idx][\"label\"])\n",
    "    same_class = (label_i == label_top1)\n",
    "\n",
    "    top1_results.append({\n",
    "        \"image_index\": i,\n",
    "        \"top1_index\": top1_idx,\n",
    "        \"top1_similarity\": round(top1_sim, 5),\n",
    "        \"label\": label_i,\n",
    "        \"top1_label\": label_top1,\n",
    "        \"same_class\": same_class\n",
    "    })\n",
    "\n",
    "# Ment√©s\n",
    "df_top1 = pd.DataFrame(top1_results)\n",
    "df_top1.to_csv(\"C:/Users/Adam/Desktop/applied_ml/image_top1_similarity.csv\", index=False)\n",
    "print(\"‚úÖ K√©sz: image_top1_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137e8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\1715302535.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\1715302535.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Cosine similarity m√°trix sz√°mol√°sa...\n",
      "üìä Recall@K sz√°mol√°sa minden k√©pre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recall k√©penk√©nt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6552/6552 [00:08<00:00, 764.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà √Åtlagos Recall@K √©rt√©kek:\n",
      "Recall@1: 0.01568\n",
      "Recall@5: 0.07727\n",
      "Recall@10: 0.15266\n",
      "Recall@20: 0.29798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity m√°trix (n x n)\n",
    "print(\"üß† Cosine similarity m√°trix sz√°mol√°sa...\")\n",
    "embedding_matrix = embeddings.numpy()\n",
    "sim_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "# Diagon√°lisan -1, hogy √∂nmag√°t ne hozza vissza\n",
    "np.fill_diagonal(sim_matrix, -1)\n",
    "\n",
    "# Recall@K √©rt√©kek\n",
    "K_values = [1, 5, 10, 20]\n",
    "recall_records = []\n",
    "\n",
    "print(\"üìä Recall@K sz√°mol√°sa minden k√©pre...\")\n",
    "for i in tqdm(range(sim_matrix.shape[0]), desc=\"Recall k√©penk√©nt\"):\n",
    "    true_label = int(infos[i][\"label\"])\n",
    "    top_indices = np.argsort(-sim_matrix[i])  # descending sorrend\n",
    "\n",
    "    recalls = {}\n",
    "    # Az aktu√°lis oszt√°lyhoz tartoz√≥ k√©pek sz√°ma (√∂nmag√°t kiv√©ve)\n",
    "    total_same_class = sum(1 for j in range(len(infos)) if j != i and int(infos[j][\"label\"]) == true_label)\n",
    "\n",
    "    for k in K_values:\n",
    "        top_k = top_indices[:k]\n",
    "        correct = sum(1 for j in top_k if int(infos[j][\"label\"]) == true_label)\n",
    "        recall = correct / total_same_class if total_same_class > 0 else 0.0\n",
    "        recalls[f\"recall@{k}\"] = round(recall, 5)\n",
    "\n",
    "    recall_records.append({\n",
    "        \"image_index\": i,\n",
    "        \"label\": true_label,\n",
    "        **recalls\n",
    "    })\n",
    "\n",
    "# DataFrame ment√©s\n",
    "df_recall = pd.DataFrame(recall_records)\n",
    "df_recall.to_csv(\"C:/Users/Adam/Desktop/applied_ml/image_recall_at_k.csv\", index=False)\n",
    "\n",
    "# √Åtlag recall@k ki√≠r√°s\n",
    "mean_recalls = df_recall[[f\"recall@{k}\" for k in K_values]].mean()\n",
    "print(\"\\nüìà √Åtlagos Recall@K √©rt√©kek:\")\n",
    "for k in K_values:\n",
    "    print(f\"Recall@{k}: {round(mean_recalls[f'recall@{k}'], 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\349315602.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\349315602.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Cosine similarity m√°trix sz√°mol√°sa...\n",
      "üìä Average Precision sz√°m√≠t√°sa minden k√©pre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AP per image: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6552/6552 [00:13<00:00, 486.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_index  label  average_precision\n",
      "0            0      1            0.80528\n",
      "1            1      1            0.80784\n",
      "2            2      1            0.80397\n",
      "3            3      1            0.79885\n",
      "4            4      1            0.77852\n",
      "\n",
      "üìà Mean Average Precision (mAP) for images: 0.8723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity m√°trix\n",
    "print(\"üß† Cosine similarity m√°trix sz√°mol√°sa...\")\n",
    "embedding_matrix = embeddings.numpy()\n",
    "sim_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "# Saj√°t mag√°t nem hasonl√≠tjuk (AP-ben nincs √©rtelme)\n",
    "np.fill_diagonal(sim_matrix, -1)\n",
    "\n",
    "# Eredm√©nyek\n",
    "ap_results = []\n",
    "\n",
    "print(\"üìä Average Precision sz√°m√≠t√°sa minden k√©pre...\")\n",
    "for i in tqdm(range(sim_matrix.shape[0]), desc=\"AP per image\"):\n",
    "    label = int(infos[i][\"label\"])\n",
    "\n",
    "    # Ground truth: 1 ha ugyanabba az oszt√°lyba tartozik, k√ºl√∂nben 0 (√∂nmag√°t nem sz√°m√≠tjuk)\n",
    "    gt = np.array([1 if int(infos[j][\"label\"]) == label else 0 for j in range(len(infos))])\n",
    "    gt[i] = 0  # √∂nmag√°t null√°zzuk\n",
    "\n",
    "    scores = sim_matrix[i]\n",
    "\n",
    "    if gt.sum() > 0:\n",
    "        ap = average_precision_score(gt, scores)\n",
    "    else:\n",
    "        ap = 0.0\n",
    "\n",
    "    ap_results.append({\n",
    "        \"image_index\": i,\n",
    "        \"label\": label,\n",
    "        \"average_precision\": round(ap, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame + mAP\n",
    "df_ap = pd.DataFrame(ap_results)\n",
    "mean_ap = df_ap[\"average_precision\"].mean()\n",
    "print(df_ap.head())\n",
    "print(f\"\\nüìà Mean Average Precision (mAP) for images: {round(mean_ap, 5)}\")\n",
    "\n",
    "# Ment√©s\n",
    "df_ap.to_csv(\"C:/Users/Adam/Desktop/applied_ml/image_average_precision.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
